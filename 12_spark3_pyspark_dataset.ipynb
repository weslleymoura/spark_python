{"cells":[{"cell_type":"markdown","source":["## Introdução aos Datasets\nNeste notebook farei uma rápida introdução ao uso de Datasets!"],"metadata":{}},{"cell_type":"markdown","source":["### Importando as bibliotecas\nNesta etapa iremos apenas importar todas as bibliotecas e funções necessárias para rodar o programa"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Criando uma SparkSession\nPor meio de uma SparkSession terei acesso ao SparkContext da minha aplicação."],"metadata":{}},{"cell_type":"code","source":["spark = SparkSession.builder.appName('Select').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["### Carregando os dados\nNesta etapa estamos carregando os dados que utilizaremos neste notebook"],"metadata":{}},{"cell_type":"code","source":["dados = spark \\\n    .read.option(\"header\",\"true\") \\\n    .option(\"inferSchema\",\"true\") \\\n    .option(\"delimiter\",\";\") \\\n    .format(\"csv\") \\\n    .load(\"/FileStore/tables/bank_additional_full-3fd09.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### O que é um Dataset?\n<p>Dizemos que Dataframes são Datasets do tipo Row, porque cada linha do meu Dataframe é composta por um objeto da classe Row\nQuando utilizamos Datasets, podemos alterar este objeto do tipo Row para um objeto definido por nós mesmos. Tecnicamente, este objeto será\ndefinido por uma Case Class (se for escrito em Scala) ou um Java Bean (se for escrito em Java)\nEsta flexibilidade vem com um custo na questão do desempenho\n\n<p>Portanto, você deve preferir usar Datasets se:\n* Não for possível realizar sua operação com Dataframes ou\n* Você precisa de tipos de dados bem definidos (type-safety). Por exemplo, uma subtração entre duas Strings vai falhar durante a compilação\ndo código (e não em tempo de execução).\n\n<p>Sempre leve esses pontos em consideracao, já que o uso de datasets prejudicará o desempenho."],"metadata":{}},{"cell_type":"code","source":["case class Bank (\n    AGE: Int,\n    JOB: String,\n    MARITAL: String,\n    EDUCATION: String,\n    DEFAULT: String,\n    HOUSING: String,\n    LOAN: String,\n    CONTACT: String,\n    MONTH: String,\n    DAY_OF_WEEK: String,\n    DURATION: String,\n    CAMPAIGN: Int,\n    PDAYS: Int,\n    PREVIOUS: Int,\n    POUTCOME: String,\n    `EMP.VAR.RATE`: Double,\n    `CONS.PRICE.IDX`: Double,\n    `CONS.CONF.IDX`: Double,\n    EURIBOR3M: Double,\n    `NR.EMPLOYED`: Double,\n    Y: String\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-2586057201697949&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">1</span>\n<span class=\"ansi-red-fg\">    case class Bank (</span>\n             ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["### Converte para Dataset"],"metadata":{}},{"cell_type":"code","source":["dataset = dados.as[Bank]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Verificando os tipos de objetos"],"metadata":{}},{"cell_type":"code","source":["dados"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["dataset"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### Exibindo alguns registros do dataset"],"metadata":{}},{"cell_type":"code","source":["dataset.show(5)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Basicamente, tudo que podemos fazer com Dataframes também é aceito em Datasets.<br>"],"metadata":{}},{"cell_type":"markdown","source":["### Obrigado!\nQuer construir uma carreira em Data Science? Acesse meu blog pessoal em https://www.hackinganalytics.com/"],"metadata":{}}],"metadata":{"name":"12_spark3_pyspark_dataset","notebookId":2586057201697916},"nbformat":4,"nbformat_minor":0}
