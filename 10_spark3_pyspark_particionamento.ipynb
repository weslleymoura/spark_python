{"cells":[{"cell_type":"markdown","source":["## Particionando Dataframes\nNeste notebook iremos aprender a particionar dados armazenados em Dataframes!"],"metadata":{}},{"cell_type":"markdown","source":["### Importando as bibliotecas\nNesta etapa iremos apenas importar todas as bibliotecas e funções necessárias para rodar o programa"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Criando uma SparkSession\nPor meio de uma SparkSession terei acesso ao SparkContext da minha aplicação."],"metadata":{}},{"cell_type":"code","source":["spark = SparkSession.builder.appName('Select').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["### Carregando os dados\nNesta etapa estamos carregando os dados que utilizaremos neste notebook"],"metadata":{}},{"cell_type":"code","source":["dados = spark \\\n    .read.option(\"header\",\"true\") \\\n    .option(\"inferSchema\",\"true\") \\\n    .option(\"delimiter\",\";\") \\\n    .format(\"csv\") \\\n    .load(\"/FileStore/tables/bank_additional_full-3fd09.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Consulta o número de partições"],"metadata":{}},{"cell_type":"code","source":["dados.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: 2</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["**Consulta o número de registros em cada partição**"],"metadata":{}},{"cell_type":"code","source":["dados.rdd.glom().map(lambda x: len(x)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[33]: [29543, 11645]</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### Reduzindo o número de partições de um dataframe"],"metadata":{}},{"cell_type":"code","source":["dados1 = dados.coalesce(1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["dados1.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[35]: 1</div>"]}}],"execution_count":14},{"cell_type":"code","source":["dados1.rdd.glom().map(lambda x: len(x)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[36]: [41188]</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["### Aumentando o número de partições"],"metadata":{}},{"cell_type":"code","source":["dados2 = dados.repartition(4)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["dados2.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[38]: 4</div>"]}}],"execution_count":18},{"cell_type":"code","source":["dados2.rdd.glom().map(lambda x: len(x)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[39]: [10297, 10297, 10296, 10298]</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["### Diferença entre coalesce e repartition\nCoalesce vai tentar organizar os dados das partições existentes apenas transferindo dados de algumas partições (que serão eliminadas)\npara outras (que serão incrementadas). Não é necessário uma operação de full shuffle para reorganizar os dados e por isso é mais rápido do que o repartition.\n<p>Por este mesmo motivo, não é possível usar o coalesce para aumentar o número de partições.\nJá o repartition faz um full suffle nas partições para reorganizá-las."],"metadata":{}},{"cell_type":"markdown","source":["### Criando partições com base no valor de uma coluna.\nPor padrão, quando fazemos particionamento por coluna, Spark vai criar 200 partições.<br>\nNeste caso, temos uma partição para cada valor da coluna \"marital\" e o restante são partições vazias"],"metadata":{}},{"cell_type":"code","source":["dados3 = dados.repartition(\"marital\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["dados3.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[41]: 200</div>"]}}],"execution_count":23},{"cell_type":"code","source":["dados3.rdd.glom().map(lambda x: len(x)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[42]: [0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 80,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 4612,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 24928,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 11568,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0]</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["**Se você quiser, pode dar um coalesce para \"countDistinct(marital) + 1\" para diminuir o número de particoes e manter seu particionamento por \"marital\"**"],"metadata":{}},{"cell_type":"code","source":["dados4 = dados3.coalesce(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["dados4.rdd.glom().map(lambda x: len(x)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[44]: [80, 4612, 24928, 11568, 0]</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["### Considerações sobre particionamento\n\nEm uma situação normal de um ambiente de cluster, Spark não vai tentar usar todos os recursos disponíveis para\nexecutar suas operações. Isso só vai acontecer se você configurar o nível de paralelismo de suas operações com um valor\nalto suficiente para que o cluster seja utilizado por inteiro.\n\n<p>Por exemplo, Spark define automaticamente o número de tarefas map para rodar em um determinado arquivo de acordo com o\nseu tamanho (embora seja possível configurar este comportamento por meio do parâmetro opcional SparkContext.textFile).\nJá para operações de reduce Spark automaticamente usa a quantidade de partições do maior RDD envolvido na operação.\n\n<p>Você pode configurar o nível de paralelismo do Spark por meio da configuração spark.PairRDDFunctions ou por meio da\npropriedade spark.default.parallelism\n\n<p>Na documentação do Spark é recomendado 1-3 tarefas por CPU core existente no cluster.\nVocê pode usar esta lógica para particionar seus dados e tomar melhor proveito do cluster.\n\n<p>ou seja,\n\n<p>n_partitions = n_cpu_cores * 3\n\n<p>Por fim, mais uma dica sobre particionamento:\nLogo após filtrar um dataframe com grande volume de dados, você deve pensar se deve reparticionar o seu dataframe menor ou não\n(em muitos casos vale a pena reorganizar as partições para obter ganhos de desempenho)\n\nParte da lógica desta aula teve como base o seguinte artigo:\nhttps://medium.com/@mrpowers/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4"],"metadata":{}},{"cell_type":"markdown","source":["### Obrigado!\nQuer construir uma carreira em Data Science? Acesse meu blog pessoal em https://www.hackinganalytics.com/"],"metadata":{}}],"metadata":{"name":"10_spark3_pyspark_particionamento","notebookId":2586057201698015},"nbformat":4,"nbformat_minor":0}
